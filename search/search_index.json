{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":"<p>The aim of the GLOBALISE project is to develop an online infrastructure that unlocks the key series of VOC documents and reports for advanced research methods. On this site, we share experiments and prototypes related to our datasets and infrastructure. We welcome your feedback.</p> <p>GLOBALISE is funded by the The Netherlands Organization for Scientific Research (NWO).</p>"},{"location":"#experiments","title":"Experiments","text":"<ul> <li>Word Embeddings trained on the c. 5 million pages of VOC transcriptions.</li> <li>Viewer for transcriptions of the c. 5 million pages of VOC documents that comprise the GLOBALISE corpus.</li> <li>Visualization of places occurring in the c. 5 million pages of VOC documents that comprise the GLOBALISE corpus.</li> <li>Search Interface for the General Missives of the VOC, as edited and published in 14 book volumes over the period 1960-2017.</li> <li>Text-Fabric Serialization of the General Missives of the VOC, especially suited for computational analysis of this corpus.</li> </ul>"},{"location":"experiments/GLOBALISE_Word2Vec_Lab/","title":"Word2Vec Experiment","text":"<p>Download links:</p> <ul> <li>Notebook: https://github.com/globalise-huygens/lab.globalise.huygens.knaw.nl/blob/main/docs/experiments/GLOBALISE_Word2Vec_Lab.ipynb</li> <li>Pretrained model (100 dimensions, 645MB): https://surfdrive.surf.nl/files/index.php/s/XmUIlsy33vpRdCX</li> </ul> <p>Downloading this notebook will allow you to experiment with a Word2Vec model based on the GLOBALISE Transcription (V2). You can train the model on your own data, or use the pretrained model to find similar words.</p> <p>If you use the pretrained model, download and unzip the <code>GLOBALISE.word2vec.zip</code> in a <code>data</code> directory in the same folder as this notebook. Only run the first cell, and skip to 'Loading a pretrained model' section to load the model and start experimenting.</p> In\u00a0[6]: Copied! <pre>import os\nimport sys\nimport logging\nimport pickle\n\nfrom gensim.models import Word2Vec, KeyedVectors\nfrom gensim.corpora.textcorpus import TextDirectoryCorpus\n\nfrom gensim.corpora.dictionary import Dictionary\n\nfrom gensim.parsing.preprocessing import (\n    remove_stopword_tokens,\n    remove_short_tokens,\n    lower_to_unicode,\n    strip_multiple_whitespaces,\n)\nfrom gensim.utils import deaccent, simple_tokenize, effective_n_jobs\n\nlogging.basicConfig(\n    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n)\nlogging.getLogger().setLevel(logging.INFO)\n\n# Setting\nvector_size = 100\n</pre> import os import sys import logging import pickle  from gensim.models import Word2Vec, KeyedVectors from gensim.corpora.textcorpus import TextDirectoryCorpus  from gensim.corpora.dictionary import Dictionary  from gensim.parsing.preprocessing import (     remove_stopword_tokens,     remove_short_tokens,     lower_to_unicode,     strip_multiple_whitespaces, ) from gensim.utils import deaccent, simple_tokenize, effective_n_jobs  logging.basicConfig(     format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO ) logging.getLogger().setLevel(logging.INFO)  # Setting vector_size = 100 In\u00a0[5]: Copied! <pre>! mkdir -p data &amp;&amp; wget https://datasets.iisg.amsterdam/api/access/datafile/33172?gbrecs=true -O data/globalise_transcriptions_v2_txt.tab --content-disposition\n</pre> ! mkdir -p data &amp;&amp; wget https://datasets.iisg.amsterdam/api/access/datafile/33172?gbrecs=true -O data/globalise_transcriptions_v2_txt.tab --content-disposition <pre>--2024-07-22 22:01:53--  https://datasets.iisg.amsterdam/api/access/datafile/33172?gbrecs=true\nResolving datasets.iisg.amsterdam (datasets.iisg.amsterdam)... 195.169.88.174\nConnecting to datasets.iisg.amsterdam (datasets.iisg.amsterdam)|195.169.88.174|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 399793 (390K) [text/plain]\nSaving to: \u2018data/globalise_transcriptions_v2_txt.tab\u2019\n\ndata/globalise_tran 100%[===================&gt;] 390,42K  --.-KB/s    in 0,06s   \n\n2024-07-22 22:01:53 (6,54 MB/s) - \u2018data/globalise_transcriptions_v2_txt.tab\u2019 saved [399793/399793]\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>! mkdir -p data/txt &amp;&amp; wget -i data/globalise_transcriptions_v2_txt.tab -P data/txt/ --content-disposition\n</pre> ! mkdir -p data/txt &amp;&amp; wget -i data/globalise_transcriptions_v2_txt.tab -P data/txt/ --content-disposition <p>We now have a collection of text files, in which each file represents the text per inventory number.</p> <p>The files need a bit of pre-processing before we can work with it. What needs to be done:</p> <ul> <li>Remove all lines starting with <code>#+ </code>. These are comments and not part of the text.</li> </ul> In\u00a0[7]: Copied! <pre>def preprocess_txt(file_path):\n    print(\"Processing\", file_path)\n\n    # Open the textfile\n    with open(file_path) as infile:\n        text = infile.read()\n\n    lines = []\n    for line in text.split(\"\\n\"):\n        if line.startswith(\"#+ \"):\n            continue\n        else:\n            lines.append(line)\n\n    text = \"\\n\".join(lines)\n\n    # Save the cleaned version\n    with open(file_path, \"w\") as outfile:\n        outfile.write(text)\n</pre> def preprocess_txt(file_path):     print(\"Processing\", file_path)      # Open the textfile     with open(file_path) as infile:         text = infile.read()      lines = []     for line in text.split(\"\\n\"):         if line.startswith(\"#+ \"):             continue         else:             lines.append(line)      text = \"\\n\".join(lines)      # Save the cleaned version     with open(file_path, \"w\") as outfile:         outfile.write(text) In\u00a0[\u00a0]: Copied! <pre>FOLDER = \"data/txt\"\n\nfor f in os.listdir(FOLDER):\n    filepath = os.path.join(FOLDER, f)\n    preprocess_txt(filepath)\n</pre> FOLDER = \"data/txt\"  for f in os.listdir(FOLDER):     filepath = os.path.join(FOLDER, f)     preprocess_txt(filepath) <p>Now that we have the data in a usable format, we can start processing it. We will use the Gensim library to train a Word2Vec model on the text data. For this, we first create a Corpus object that will be used to feed text to the model. We use a custom implementation of the <code>gensim.corpora.textcorpus.TextCorpus</code> class to now have a cutoff for the number of words in the vocabulary (standard settings).</p> In\u00a0[9]: Copied! <pre>logger = logging.getLogger(__name__)\n\n\nclass CustomTextDirectoryCorpus(TextDirectoryCorpus):\n    \"\"\"\n    Custom class to set the `prune_at` gensim.Dictionary parameter.\n    \"\"\"\n\n    def __init__(\n        self,\n        input,\n        dictionary=None,\n        metadata=False,\n        character_filters=None,\n        tokenizer=None,\n        token_filters=None,\n        min_depth=0,\n        max_depth=None,\n        pattern=None,\n        exclude_pattern=None,\n        lines_are_documents=False,\n        encoding=\"utf-8\",\n        dictionary_prune_at=2_000_000,\n        **kwargs,\n    ):\n        self._min_depth = min_depth\n        self._max_depth = sys.maxsize if max_depth is None else max_depth\n        self.pattern = pattern\n        self.exclude_pattern = exclude_pattern\n        self.lines_are_documents = lines_are_documents\n        self.encoding = encoding\n\n        self.dictionary_prune_at = dictionary_prune_at\n\n        self.input = input\n        self.metadata = metadata\n\n        self.character_filters = character_filters\n        if self.character_filters is None:\n            self.character_filters = [\n                lower_to_unicode,\n                deaccent,\n                strip_multiple_whitespaces,\n            ]\n\n        self.tokenizer = tokenizer\n        if self.tokenizer is None:\n            self.tokenizer = simple_tokenize\n\n        self.token_filters = token_filters\n        if self.token_filters is None:\n            self.token_filters = [remove_short_tokens, remove_stopword_tokens]\n\n        self.length = None\n        self.dictionary = None\n        self.init_dictionary(dictionary)\n\n        super(CustomTextDirectoryCorpus, self).__init__(\n            input, self.dictionary, metadata, **kwargs\n        )\n\n    def init_dictionary(self, dictionary):\n        \"\"\"Initialize/update dictionary.\n\n        Parameters\n        ----------\n        dictionary : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n            If a dictionary is provided, it will not be updated with the given corpus on initialization.\n            If None - new dictionary will be built for the given corpus.\n\n        Notes\n        -----\n        If self.input is None - make nothing.\n\n        \"\"\"\n\n        self.dictionary = dictionary if dictionary is not None else Dictionary()\n\n        if self.input is not None:\n            if dictionary is None:\n                logger.info(\"Initializing dictionary\")\n                metadata_setting = self.metadata\n                self.metadata = False\n                self.dictionary.add_documents(\n                    self.get_texts(), prune_at=self.dictionary_prune_at\n                )\n                self.metadata = metadata_setting\n            else:\n                logger.info(\"Input stream provided but dictionary already initialized\")\n        else:\n            logger.warning(\n                \"No input document stream provided; assuming dictionary will be initialized some other way.\"\n            )\n</pre> logger = logging.getLogger(__name__)   class CustomTextDirectoryCorpus(TextDirectoryCorpus):     \"\"\"     Custom class to set the `prune_at` gensim.Dictionary parameter.     \"\"\"      def __init__(         self,         input,         dictionary=None,         metadata=False,         character_filters=None,         tokenizer=None,         token_filters=None,         min_depth=0,         max_depth=None,         pattern=None,         exclude_pattern=None,         lines_are_documents=False,         encoding=\"utf-8\",         dictionary_prune_at=2_000_000,         **kwargs,     ):         self._min_depth = min_depth         self._max_depth = sys.maxsize if max_depth is None else max_depth         self.pattern = pattern         self.exclude_pattern = exclude_pattern         self.lines_are_documents = lines_are_documents         self.encoding = encoding          self.dictionary_prune_at = dictionary_prune_at          self.input = input         self.metadata = metadata          self.character_filters = character_filters         if self.character_filters is None:             self.character_filters = [                 lower_to_unicode,                 deaccent,                 strip_multiple_whitespaces,             ]          self.tokenizer = tokenizer         if self.tokenizer is None:             self.tokenizer = simple_tokenize          self.token_filters = token_filters         if self.token_filters is None:             self.token_filters = [remove_short_tokens, remove_stopword_tokens]          self.length = None         self.dictionary = None         self.init_dictionary(dictionary)          super(CustomTextDirectoryCorpus, self).__init__(             input, self.dictionary, metadata, **kwargs         )      def init_dictionary(self, dictionary):         \"\"\"Initialize/update dictionary.          Parameters         ----------         dictionary : :class:`~gensim.corpora.dictionary.Dictionary`, optional             If a dictionary is provided, it will not be updated with the given corpus on initialization.             If None - new dictionary will be built for the given corpus.          Notes         -----         If self.input is None - make nothing.          \"\"\"          self.dictionary = dictionary if dictionary is not None else Dictionary()          if self.input is not None:             if dictionary is None:                 logger.info(\"Initializing dictionary\")                 metadata_setting = self.metadata                 self.metadata = False                 self.dictionary.add_documents(                     self.get_texts(), prune_at=self.dictionary_prune_at                 )                 self.metadata = metadata_setting             else:                 logger.info(\"Input stream provided but dictionary already initialized\")         else:             logger.warning(                 \"No input document stream provided; assuming dictionary will be initialized some other way.\"             ) In\u00a0[10]: Copied! <pre>class SentencesIterator:\n    def __init__(self, generator_function):\n        self.generator_function = generator_function\n        self.generator = self.generator_function()\n\n    def __iter__(self):\n        # reset the generator\n        self.generator = self.generator_function()\n        return self\n\n    def __next__(self):\n        result = next(self.generator)\n        if result is None:\n            raise StopIteration\n        else:\n            return result\n</pre> class SentencesIterator:     def __init__(self, generator_function):         self.generator_function = generator_function         self.generator = self.generator_function()      def __iter__(self):         # reset the generator         self.generator = self.generator_function()         return self      def __next__(self):         result = next(self.generator)         if result is None:             raise StopIteration         else:             return result <p>With the above code we can generate our own 'corpus' object with a slightly bigger dictionary size than in Gensim's standard library. We set it to 20M, since we are also interested in the lesser frequent words (e.g. spelling varieties). We can filter later on minimum frequency.</p> In\u00a0[11]: Copied! <pre>corpus = CustomTextDirectoryCorpus(FOLDER, dictionary_prune_at=20_000_000)\n</pre> corpus = CustomTextDirectoryCorpus(FOLDER, dictionary_prune_at=20_000_000) <pre>2024-07-22 22:14:08,818 : INFO : Initializing dictionary\n2024-07-22 22:14:09,148 : INFO : adding document #0 to Dictionary&lt;0 unique tokens: []&gt;\n2024-07-22 22:36:27,988 : INFO : built Dictionary&lt;10195707 unique tokens: ['__o', '_os', 'aad', 'aag', 'aagwit']...&gt; from 6893 documents (total 694347987 corpus positions)\n2024-07-22 22:36:27,988 : INFO : Input stream provided but dictionary already initialized\n</pre> <p>Now let's save the corpus object to disk, so we can use it later on and don't have to re-run the pre-processing steps. Comment and uncomment the respective code below to run the pre-processing steps or load the corpus object from disk.</p> In\u00a0[12]: Copied! <pre>with open(\"data/corpus.pkl\", \"wb\") as f:\n    pickle.dump(corpus, f)\n</pre> with open(\"data/corpus.pkl\", \"wb\") as f:     pickle.dump(corpus, f) In\u00a0[13]: Copied! <pre># with open(\"data/corpus.pkl\", \"rb\") as f:\n#     corpus = pickle.load(f)\n</pre> # with open(\"data/corpus.pkl\", \"rb\") as f: #     corpus = pickle.load(f) <p>Next step is to train the Word2Vec model. For this, we need to feed it the corpus object multiple times. We do so by initializing an iterator:</p> In\u00a0[14]: Copied! <pre>texts = SentencesIterator(corpus.get_texts)\n</pre> texts = SentencesIterator(corpus.get_texts) <p>Now, let's create a Word2Vec embedding. You can set the number of workers to your CPU count (minus 1). Again, this can take a while.</p> <p>You can experiment with the parameters of the Word2Vec model, such as the vector size, window size, and minimum frequency, but this can lead to a bigger model, longer training time, and not necessarily better results.</p> In\u00a0[\u00a0]: Copied! <pre>workers = effective_n_jobs(max(os.cpu_count() - 1, 1))\nw2v = Word2Vec(\n    texts, vector_size=vector_size, window=5, min_count=5, workers=workers, epochs=5\n)\n</pre> workers = effective_n_jobs(max(os.cpu_count() - 1, 1)) w2v = Word2Vec(     texts, vector_size=vector_size, window=5, min_count=5, workers=workers, epochs=5 ) <p>Now, let's save the embedding for future use. (Similarly, there is a function to load a previously saved model again below)</p> In\u00a0[16]: Copied! <pre>w2v.wv.save_word2vec_format(f\"data/GLOBALISE_{vector_size}.word2vec\")\n</pre> w2v.wv.save_word2vec_format(f\"data/GLOBALISE_{vector_size}.word2vec\") <pre>2024-07-23 00:23:10,897 : INFO : storing 1369250x100 projection weights into data/GLOBALISE.word2vec\n</pre> In\u00a0[5]: Copied! <pre>w2v = KeyedVectors.load_word2vec_format(f\"data/GLOBALISE_{vector_size}.word2vec\")\n</pre> w2v = KeyedVectors.load_word2vec_format(f\"data/GLOBALISE_{vector_size}.word2vec\") <pre>2024-07-26 11:53:24,202 : INFO : loading projection weights from data/GLOBALISE.word2vec\n2024-07-26 11:54:03,938 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (1369250, 100) matrix of type float32 from data/GLOBALISE.word2vec', 'binary': False, 'encoding': 'utf8', 'datetime': '2024-07-26T11:54:03.938194', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-116-generic-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n</pre> <p>Now, this is where the fun starts. We can use the Word2Vec model to find similar words to a given word and thereby find words that share the same semantics and context.</p> <p>See the Gensim documentation for more information on how to use the Word2Vec model: https://radimrehurek.com/gensim/models/word2vec.html. Below are some examples of how to use the model. You can substitute the words with any word you like, as long as it is in the vocabulary of the model/corpus. Everything needs to be in lowercase.</p> In\u00a0[7]: Copied! <pre>for i in w2v.most_similar(\"pantchialang\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"pantchialang\", topn=100):     print(i[0], end=\" | \") <pre>pantchialling | pantjall | dehaij | pantch | depantjall | patchiall | pantchiall | challang | debijl | noodhulp | goudsoeker | pantsch | haaij | tapko | pantchialt | jaarvogel | depantchiall | jongedirk | buijtel | krankte | windbuijl | depantjallang | patchiallang | zuykermaalder | pantchallang | depantch | onbeschaamdh | copjagt | chialling | patchalling | boshaan | pantchiallings | salpetersoeker | overmaas | pantjalang | bonneratte | chialop | onbeschaamtheijt | pantc | patchall | patjallang | arnoldina | losboots | pantchall | desnoek | zijdeteeld | woelwater | suijkermaalder | bancq | depatchiall | kruisser | depant | debarcq | nacheribon | sorgdrager | zijdewoom | glisgis | beschutter | vantchiall | delosboot | garnaal | chailoup | beschermer | zordaan | galwet | casuaris | pandjallang | casuarus | pantj | schipio | galeij | oostendenaer | ontang | patch | burk | losboot | smapt | panthialling | bethij | breguantijn | depatch | coffijthuijn | pantsjall | contong | moesthuijn | ramsgatte | jallang | zuijerbeek | onbeschaamtheijd | pantchalling | panthiallang | pittoor | zuijkermaalder | chialoop | tanjongpour | vrctoria | vesuvius | pinxterbloem | chiloup | pantschiallang | </pre> In\u00a0[19]: Copied! <pre>for i, p in w2v.most_similar(\"amsterdam\", topn=100):\n    if p &gt;= 0.4:\n        print(i, end=\" \")\n</pre> for i, p in w2v.most_similar(\"amsterdam\", topn=100):     if p &gt;= 0.4:         print(i, end=\" \") <pre>sterdam middelburg amsterd amst zeeland amster amsterdm amstm rotterdam delft amsteldam enkhuijsen zeland middelburgh utrecht ams amsterda amste gravenhage terdam zeelant zeiland derwapen enchuijsen dam delff maddelburg middelb enckhuijsen amstedam enkhuijzen aamsterdam delfft presidiale enkhuisen seeland enckhuijzen geredreseert vlissingen rdam praesidiale amsterdan hage costeux zeelandt wappan hoorn rotterdant delburg delf delst behangsels inzeland middelbrerg enkhuizen proefidiaale praecidiale ceulen boodh caamer enckhuijs dewees behanghsel amsterstam temiddelburg enkhuysen zieland alkmaar meddelburg cognoissemet rotter sdh carode uijtgevaren middelburgin kameer delvt leijden zeel praesideale amstd uijtregt utregt hoplooper enchuy terkamer rabbinel vlissinge diale kaner veere arnhem confernee praesidiaale haarlem kamier enehuysen siemermeer middeburg amstdam </pre> In\u00a0[20]: Copied! <pre>for i in w2v.most_similar(\"intje\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"intje\", topn=100):     print(i[0], end=\" | \") <pre>jntje | maleijer | dul | maleyer | anachoda | bappa | salim | jntie | malijer | malaijer | malim | boeginees | jurragan | parnakan | iavaan | iuragan | intie | cadier | sadulla | carim | mochamat | abdul | samat | parnackan | javaan | arabier | assan | nachoda | javaen | soedin | bouginees | mohamat | abdulla | achmat | talip | iurragan | inw | kinko | balier | zait | jnw | lim | sleman | juragan | saijit | garrang | rahim | bagus | oeij | tjina | anach | njo | jabar | boeang | tjan | mahama | karim | boeijong | aboe | jnwoonder | ganie | campar | tja | garang | balijer | troena | kamat | mallijer | anak | chin | sait | cassim | machoda | boejong | soekoer | roekoe | nio | samara | oemar | poea | lebe | hoko | miskien | vrijbalier | maijang | hoeko | salee | sech | samsoe | boegenees | naghoda | koko | gonting | tenoedin | mandarees | oesien | troeno | draman | sinko | jamal | </pre> In\u00a0[21]: Copied! <pre>for i in w2v.most_similar(\"caneel\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"caneel\", topn=100):     print(i[0], end=\" | \") <pre>canneel | arreecq | arreeck | cardamom | geschilden | balen | cardaman | cardamon | areecq | arreek | geschilt | overjarigen | areek | geschilde | ruijnas | bast | kurkuma | wortelen | wortel | cardemom | cannel | saffragamse | arreeq | groven | jndigo | incorrecte | ammenams | schelders | plantjes | curcuma | areeck | ougsten | affpacken | zaije | runas | schillens | moernagelen | cauwa | wortels | smakeloose | koehuijden | klenen | indigo | gekookten | zalpeter | canneer | saije | calpentijnsen | cragtelose | endeneese | canneelschilders | cheijlonsen | kannee | reuck | baelen | baalen | kanneel | pingos | sacken | varssen | anijl | ruinas | ammonams | tabacq | zaat | cauris | amm | ruias | cardanom | fijnen | cardamam | coffijbonen | cardamoin | arreck | bhaalen | zaijen | nagelen | caneell | embaleeren | bladeren | berberijen | coffijboonen | overjarige | kleenen | fordeelen | zaad | onrijpe | noten | pken | specerije | gamsen | geschild | caaneel | roggevellen | endeneesche | ingesamelden | oliteiten | peerlen | pepen | elijhanten | </pre> In\u00a0[22]: Copied! <pre>for i in w2v.most_similar(\n    positive=[\"weder\", \"weer\", \"regen\"], negative=[\"wederom\", \"alweder\"], topn=100\n):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(     positive=[\"weder\", \"weer\", \"regen\"], negative=[\"wederom\", \"alweder\"], topn=100 ):     print(i[0], end=\" | \") <pre>weir | reegen | wint | zeewint | lugt | windt | noorde | winden | waaijende | stroom | buijen | winde | sneeuw | doorwaijen | zuijde | lucht | regenbuijen | waijende | wind | coeltjens | suijdweste | koude | vlagen | handsaem | weerligt | dewind | regenagtig | tegenstroom | doorwaijende | sonneschijn | regenen | stilte | koelte | regens | coelte | lught | hitte | stijve | lughje | zeewind | wintje | weste | warme | onstuijmig | reegenen | stroomen | koelten | zonnestraalen | delugt | warmte | handsaam | buijdige | travaden | doorbreken | inbreeken | moussom | doorwaaijende | reegende | travadig | doorstaande | doorkomende | hette | buijig | luchje | felle | afwatering | starke | kentering | overdag | stormwinden | reegens | wzw | westelijke | vloet | variable | coeltje | calte | tegenwinden | ooste | goedweer | oostelijke | noordweste | zot | waaijde | deijning | aartrijk | noordelijk | valwinden | ongestadige | doorwaaijen | slijve | suijde | caelte | lugties | firmament | regende | coeste | travodig | coelende | doorbrake | </pre> In\u00a0[23]: Copied! <pre>w2v.closer_than(\"eendracht\", \"tilburg\")\n</pre> w2v.closer_than(\"eendracht\", \"tilburg\") Out[23]: <pre>['ende',\n 'naer',\n 'oock',\n 'noch',\n 'int',\n 'nae',\n 'schepen',\n 'retour',\n 'vant',\n 'camer',\n 'gecomen',\n 'fluijt',\n 'volck',\n 'becomen',\n 'welck',\n 'jacht',\n 'hoorn',\n 'japan',\n 'rotterdam',\n 'coninck',\n 'ditto',\n 'jagt',\n 'wint',\n 'compe',\n 'godt',\n 'lant',\n 'eijlanden',\n 'derwaerts',\n 'end',\n 'vertreck',\n 'landt',\n 'goa',\n 'geladen',\n 'stadt',\n 'tschip',\n 'bat',\n 'comende',\n 'maent',\n 'opt',\n 'chaloup',\n 'maecken',\n 'ladinge',\n 'japara',\n 'delft',\n 'oocq',\n 'gearriveert',\n 'genaemt',\n 'gemaeckt',\n 'weijnich',\n 'coningh',\n 'rhede',\n 'langh',\n 'waermede',\n 'daermede',\n 'ene',\n 'macht',\n 'ancker',\n 'originele',\n 'jnt',\n 'eijlant',\n 'nassauw',\n 'augustij',\n 'vrede',\n 'quartieren',\n 'wapen',\n 'voijagie',\n 'cattij',\n 'middagh',\n 'achter',\n 'opde',\n 'vaderlant',\n 'portugees',\n 'geseijde',\n 'leeuw',\n 'dirck',\n 'cargasoen',\n 'verwachten',\n 'mauritius',\n 'rijck',\n 'chialoep',\n 'dach',\n 'namentlijck',\n 'eijlandt',\n 'geladene',\n 'vlissingen',\n 'jachten',\n 'battavia',\n 'gelyck',\n 'seecker',\n 'wingurla',\n 'gescheept',\n 'amst',\n 'portugesen',\n 'iapan',\n 'comste',\n 'stondt',\n 'nederlants',\n 'arent',\n 'nacht',\n 'vercocht',\n 'haven',\n 'zielen',\n 'caap',\n 'gedestineert',\n 'goens',\n 'fregat',\n 'vaert',\n 'oosten',\n 'galjoot',\n 'iagt',\n 'bouton',\n 'admirael',\n 'baij',\n 'aengecomen',\n 'eenich',\n 'orangie',\n 'besendinge',\n 'nde',\n 'batt',\n 'joncken',\n 'toecomende',\n 'journael',\n 'fortuijn',\n 'conincx',\n 'volladen',\n 'enkhuijsen',\n 'gevaren',\n 'amsterd',\n 'engeland',\n 'diemen',\n 'japanse',\n 'suratte',\n 'texel',\n 'souratte',\n 'vaeren',\n 'moluccos',\n 'hooch',\n 'cleen',\n 'vandaer',\n 'vaertuijgh',\n 'aent',\n 'noorden',\n 'vloote',\n 'windt',\n 'loo',\n 'noort',\n 'havenen',\n 'jager',\n 'jans',\n 'ganges',\n 'gedestineerde',\n 'jagtje',\n 'mallacca',\n 'westen',\n 'reyse',\n 'twelcke',\n 'helena',\n 'claes',\n 'swarten',\n 'sumatra',\n 'suijcker',\n 'speelman',\n 'datmen',\n 'concordia',\n 'lam',\n 'burgh',\n 'bon',\n 'geseijlt',\n 'geseijt',\n 'wech',\n 'ouer',\n 'wacht',\n 'princes',\n 'vijant',\n 'uijren',\n 'vertreckt',\n 'lanck',\n 'vaderlandt',\n 'sunda',\n 'suratta',\n 'koninck',\n 'dittos',\n 'naderhant',\n 'mette',\n 'spiegel',\n 'eendragt',\n 'welvaren',\n 'graden',\n 'metten',\n 'wester',\n 'cleijn',\n 'oorloge',\n 'hollandia',\n 'avondt',\n 'mars',\n 'chaloupen',\n 'queda',\n 'hoecker',\n 'engelsz',\n 'malcanderen',\n 'maen',\n 'ternate',\n 'lichten',\n 'eenighe',\n 'velsen',\n 'boeckhouder',\n 'hoeck',\n 'soodanich',\n 'eenelijck',\n 'aer',\n 'vijandt',\n 'fluijten',\n 'toegecomen',\n 'leijt',\n 'becoomen',\n 'pauw',\n 'pallas',\n 'stierman',\n 'seijlen',\n 'jaght',\n 'bengala',\n 'beer',\n 'gelicht',\n 'seijl',\n 'zuijt',\n 'nangasackij',\n 'lants',\n 'nederlantse',\n 'eijndelijck',\n 'anthonio',\n 'jonck',\n 'facture',\n 'anckers',\n 'monterende',\n 'esperance',\n 'schagen',\n 'jegenwoordich',\n 'opperhooffden',\n 'monteert',\n 'geprojecteert',\n 'eylanden',\n 'taijouan',\n 'persien',\n 'aengebracht',\n 'brant',\n 'macquian',\n 'straet',\n 'schep',\n 'ladingh',\n 'portugese',\n 'ouglij',\n 'alreede',\n 'lis',\n 'insgelijcx',\n 'maes',\n 'besettinge',\n 'macao',\n 'haas',\n 'geraeckt',\n 'fluijtje',\n 'caep',\n 'zeelandia',\n 'gemaect',\n 'joris',\n 'twelcq',\n 'selvige',\n 'spoedigh',\n 'doort',\n 'zeelant',\n 'nassau',\n 'retourneren',\n 'overgecomen',\n 'oorsaecke',\n 'bantham',\n 'middach',\n 'nodich',\n 'rechte',\n 'naert',\n 'martij',\n 'costi',\n 'welcq',\n 'overnes',\n 'voorss',\n 'waert',\n 'maendt',\n 'siams',\n 'verrichten',\n 'cauw',\n 'middelburgh',\n 'sillida',\n 'snoek',\n 'tidoor',\n 'brugge',\n 'zeijlende',\n 'voornt',\n 'ouwerkerk',\n 'naervolgende',\n 'conincq',\n 'aenstonts',\n 'wederomme',\n 'elck',\n 'gesecht',\n 'fredrick',\n 'cast',\n 'volcht',\n 'diamant',\n 'jaerlijcx',\n 'dieren',\n 'mouson',\n 'compste',\n 'opden',\n 'genoech',\n 'batavier',\n 'vaertuijch',\n 'geraecken',\n 'middelb',\n 'reste',\n 'chial',\n 'reviere',\n 'adrichem',\n 'castricum',\n 'tegenwoordich',\n 'vracht',\n 'margaretha',\n 'overschie',\n 'damme',\n 'spijk',\n 'grave',\n 'horst',\n 'dicht',\n 'biema',\n 'engelant',\n 'terstont',\n 'jagten',\n 'doornik',\n 'tocht',\n 'gecocht',\n 'siecken',\n 'lagh',\n 'amboijna',\n 'redelijck',\n 'nieuwland',\n 'verovert',\n 'arriveren',\n 'capelle',\n 'verwacht',\n 'gecregen',\n 'cargasoenen',\n 'houdt',\n 'scheepie',\n 'raap',\n 'ooc',\n 'hillegonda',\n 'overgescheept',\n 'onderwegen',\n 'hollantse',\n 'voorder',\n 'nassouw',\n 'vruchten',\n 'brandt',\n 'oma',\n 'westhoven',\n 'ongeluck',\n 'spiering',\n 'sijmon',\n 'goes',\n 'fluijtschip',\n 'selue',\n 'reij',\n 'geankert',\n 'bort',\n 'hercules',\n 'verbij',\n 'hoet',\n 'gelijcq',\n 'gezeijlt',\n 'gesamentlijck',\n 'vrijburg',\n 'manilha',\n 'havens',\n 'thoff',\n 'oudt',\n 'naderhandt',\n 'negombo',\n 'walcheren',\n 'opperdoes',\n 'breda',\n 'pegu',\n 'solor',\n 'joncke',\n 'mallebaer',\n 'chiampan',\n 'voorspoet',\n 'redout',\n 'naerde',\n 'batavise',\n 'boa',\n 'jappan',\n 'briel',\n 'abbekerk',\n 'sont',\n 'tijdingh',\n 'weynich',\n 'geseth',\n 'meijnden',\n 'vliegende',\n 'woerden',\n 'vaderlantse',\n 'genaempt',\n 'wilhem',\n 'achteren',\n 'paliacatta',\n 'steecken',\n 'alst',\n 'boero',\n 'zeelandt',\n 'langewijk',\n 'riviere',\n 'formosa',\n 'adelborst',\n 'mettet',\n 'mett',\n 'caron',\n 'leck',\n 'tjagt',\n 'ano',\n 'snauw',\n 'broeck',\n 'tjacht',\n 'erasmus',\n 'manilhas',\n 'witten',\n 'beverwijk',\n 'utrecht',\n 'quaemen',\n 'gouda',\n 'cats',\n 'atchin',\n 'ingeladen',\n 'enckhuijsen',\n 'verricht',\n 'coen',\n 'vlaming',\n 'claesz',\n 'larique',\n 'brandenburg',\n 'grondt',\n 'molucco',\n 'aendoen',\n 'come',\n 'duijnen',\n 'vuijt',\n 'armade',\n 'iacoba',\n 'boucken',\n 'firando',\n 'moij',\n 'unie',\n 'dolphijn',\n 'daerse',\n 'foreest',\n 'kat',\n 'thof',\n 'joncq',\n 'geruchten',\n 'haen',\n 'cha',\n 'flora',\n 'amb',\n 'spoedich',\n 'keulen',\n 'saterdagh',\n 'janssen',\n 'campen',\n 'aencomste',\n 'vaerwater',\n 'date',\n 'standt',\n 'haerlem',\n 'fluyt',\n 'chaloep',\n 'jaccatra',\n 'dienstich',\n 'bassora',\n 'veroverde',\n 'deense',\n 'aenboort',\n 'castel',\n 'baije',\n 'assenburg',\n 'reeckeninge',\n 'buuren',\n 'hoochte',\n 'paert',\n 'besendingh',\n 'bellasoor',\n 'hurdt',\n 'africa',\n 'engelandt',\n 'barentsz',\n 'drije',\n 'gemant',\n 'victorie',\n 'coeverden',\n 'gescheepte',\n 'etmael',\n 'borsselen',\n 'baeij',\n 'samson',\n 'inlants',\n 'zunda',\n 'besuijden',\n 'nieuwerkerk',\n 'valck',\n 'blijdorp',\n 'chialoepen',\n 'eten',\n 'redelijcke',\n 'mitsgaeders',\n 'delfs',\n 'oosthuijsen',\n 'sulckx',\n 'henrick',\n 'westerbeek',\n 'brugh',\n 'nas',\n 'tland',\n 'vaem',\n 'riff',\n 'antonio',\n 'hollant',\n 'nederlantsche',\n 'schulp',\n 'cruijs',\n 'verongelucken',\n 'wassenaar',\n 'londen',\n 'nachts',\n 'beschermer',\n 'geraackt',\n 'outshoorn',\n 'maendagh',\n 'wercq',\n 'nederlant',\n 'opperstierman',\n 'rijckloff',\n 'gecombineert',\n 'aengeweest',\n 'naght',\n 'voorburg',\n 'strandt',\n 'waveren',\n 'reduijt',\n 'cregen',\n 'noordbeek',\n 'draak',\n 'jaques',\n 'suijder',\n 'ellemeet',\n 'nova',\n 'nuijts',\n 'gelaeden',\n 'pool',\n 'besoecken',\n 'vosmaar',\n 'castor',\n 'retourneert',\n 'oct',\n 'schepe',\n 'comptanten',\n 'herstelde',\n 'onderzeijl',\n 'wickenburg',\n 'popkensburg',\n 'oorloch',\n 'steenhoven',\n 'vlamingh',\n 'bonne',\n 'seijnden',\n 'werwaerts',\n 'straalen',\n 'bijt',\n 'theodora',\n 'kercke',\n 'hogersmilde',\n 'tanjongpoura',\n 'datelijck',\n 'terra',\n 'iager',\n 'derwarts',\n 'dto',\n 'rotterd',\n 'aengeland',\n 'cijlon',\n 'soot',\n 'gideon',\n 'gevolcht',\n 'vertrocke',\n 'samarangh',\n 'hoedanich',\n 'gestevent',\n 'hollandt',\n 'herwarts',\n 'meerman',\n 'wesel',\n 'alphen',\n 'raeckende',\n 'iacht',\n 'twapen',\n 'alsvooren',\n 'parsia',\n 'ledigh',\n 'amstel',\n 'enchuijsen',\n 'masulipatam',\n 'rosingijn',\n 'vane',\n 'vestinge',\n 'papenburg',\n 'ontladen',\n 'valkenisse',\n 'reeckeningh',\n 'voorgemelte',\n 'tarnaten',\n 'gangh',\n 'laeden',\n 'hoochsten',\n 'ock',\n 'breecken',\n 'robbertus',\n 'booth',\n 'peerl',\n 'gouw',\n 'eylant',\n 'schelde',\n 'langhs',\n 'boordt',\n 'wendela',\n 'eenhoorn',\n 'voorland',\n 'faam',\n 'visvliet',\n 'beoosten',\n 'iagtje',\n 'salm',\n 'clachten',\n 'gevaeren',\n 'perijckel',\n 'redel',\n 'naet',\n 'seijlon',\n 'alsem',\n 'bocht',\n 'besich',\n 'leyden',\n 'groeningen',\n 'haerder',\n 'carthago',\n 'vruchteloos',\n 'maleijo',\n 'block',\n 'hardt',\n 'rhoon',\n 'wijck',\n 'genoechsaem',\n 'oostrust',\n 'waerdich',\n 'pollux',\n 'verseeckeringe',\n 'gesicht',\n 'mane',\n 'aancomste',\n 'geduijrende',\n 'besettingh',\n 'portugael',\n 'passerende',\n 'raadhuijs',\n 'rijcke',\n 'cargo',\n 'vertrecq',\n 'lampon',\n 'scholtenburg',\n 'palimbangh',\n 'deensche',\n 'amerongen',\n 'veroorsaeckt',\n 'enge',\n 'bogaart',\n 'choromandel',\n 'chirrebon',\n 'delff',\n 'bijweg',\n 'landskroon',\n 'alsnoch',\n 'bevindingh',\n 'menichte',\n 'sint',\n 'beseth',\n 'vijants',\n 'ridderkerk',\n 'westerveld',\n 'schiedam',\n 'beekvliet',\n 'comptant',\n 'padmos',\n 'retourneerende',\n 'naart',\n 'geseijden',\n 'aencomende',\n 'nederlandt',\n 'aden',\n 'becommen',\n 'maccauw',\n 'byden',\n 'crab',\n 'cronenburg',\n 'aenkomste',\n 'vlucht',\n 'eylandt',\n 'haes',\n 'waerden',\n 'purmer',\n 'correcorren',\n 'tack',\n 'majt',\n 'alsnu',\n 'verseijlt',\n 'zuratta',\n 'slach',\n 'scheepken',\n 'strijen',\n 'middelwout',\n 'verwachtende',\n 'zeepaard',\n 'brachten',\n 'beijeren',\n 'dregterland',\n 'geertruij',\n 'casar',\n 'javan',\n 'ceres',\n 'aencomen',\n 'hendricksz',\n 'tpatria',\n 'snachts',\n 'gevolght',\n 'ida',\n 'eijl',\n 'jonghst',\n 'triton',\n 'mandorijn',\n 'voorwaer',\n 'ome',\n 'corts',\n 'spaens',\n 'meerlust',\n 'dircksz',\n 'merwe',\n 'voorschooten',\n 'patanij',\n 'hogenes',\n 'borneo',\n 'eem',\n 'vertimmeren',\n 'vlote',\n 'nederhoven',\n 'rosenburg',\n 'jnlants',\n 'oranje',\n 'fregatten',\n 'ria',\n 'naerden',\n 'maldives',\n 'beveland',\n 'bodt',\n 'selffde',\n 'daechs',\n 'nass',\n 'negrij',\n 'purmerlust',\n 'uijr',\n 'overcomste',\n 'vaderlants',\n 'goas',\n 'ceulen',\n 'veroveren',\n 'jerusalem',\n 'defluijt',\n 'limburg',\n 'geseyde',\n 'hopvogel',\n 'rebecca',\n 'azia',\n 'chiampans',\n 'punct',\n 'veere',\n 'gaasperdam',\n 'uno',\n 'crap',\n 'lastdrager',\n 'sleewijk',\n 'verbrant',\n 'suijt',\n 'suijckeren',\n 'phenix',\n 'vicq',\n 'padtbrugge',\n 'lach',\n 'januario',\n 'aengelant',\n 'zuijderburg',\n 'medebrengende',\n 'geanckert',\n 'malcander',\n 'merckt',\n 'coomende',\n 'voorstaende',\n 'aes',\n 'maleijen',\n 'osacca',\n 'vreeland',\n 'leste',\n 'suijd',\n 'batavi',\n 'daghregister',\n 'partie',\n 'terdam',\n 'schoonderloo',\n 'cruijssen',\n 'maleije',\n 'calpentijn',\n 'vriesland',\n 'geus',\n 'renswoude',\n 'kerkwijk',\n 'westerdijxhorn',\n 'delfshaven',\n 'oostende',\n 'geroerde',\n 'vlagh',\n 'zeel',\n 'gissingh',\n 'geberchte',\n 'duijnenburg',\n 'sar',\n 'fluijtie',\n 'herstelder',\n 'duijven',\n 'schuijtwijk',\n 'thuys',\n 'aatchin',\n 'tcasteel',\n 'verongeluckte',\n 'vojagie',\n 'vrientschap',\n 'horstendaal',\n 'loenderveen',\n 'dordrecht',\n 'verseijlen',\n 'liggen',\n 'milde',\n 'madrast',\n 'aleppo',\n 'pantchiall',\n 'nieuwstad',\n 'barbara',\n 'meijenberg',\n 'dieshoek',\n 'carpentier',\n 'gevlucht',\n 'brack',\n 'weeck',\n 'schoonauwen',\n 'bombahia',\n 'macas',\n 'geertruijd',\n 'voorschoten',\n 'amadabath',\n 'mathijs',\n 'beeck',\n 'schellag',\n 'spoedichste',\n 'sparenrijk',\n 'graeff',\n 'jacatra',\n 'uijtgaen',\n 'voyagie',\n 'diemermeer',\n 'stieren',\n 'mourits',\n 'jorisz',\n 'gemaeckte',\n 'gestadich',\n 'aetchin',\n 'jonghste',\n 'schips',\n 'junius',\n 'crooswijk',\n 'andragirij',\n 'paauw',\n 'bellesoor',\n 'berkenroode',\n 'mijdregt',\n 'robijn',\n 'naede',\n 'deventer',\n 'sielen',\n 'kroonenburg',\n 'mondt',\n 'gheijn',\n 'ziam',\n 'hulst',\n 'palembangh',\n 'ael',\n 'verwachte',\n 'vegt',\n 'midts',\n 'alrede',\n 'superintendent',\n 'horssen',\n 'pampus',\n 'laer',\n 'zuyd',\n 'aengebrachte',\n 'caeb',\n 'hittoe',\n 'raecken',\n 'daman',\n 'prattenburg',\n 'frederick',\n 'vlotter',\n 'lichte',\n 'gecombineerd',\n 'landts',\n 'doradus',\n 'jamby',\n 'vroech',\n 'putmans',\n 'bril',\n 'maetsuijcker',\n 'maccao',\n 'delfland',\n 'kronenburg',\n 'bengaele',\n 'makassar',\n 'salanghoor',\n 'proostwijk',\n 'rescontre',\n 'perde',\n 'rosairo',\n 'tydinge',\n 'gemerct',\n 'ijsselmonde',\n 'giroffel',\n 'kiefhoek',\n 'eend',\n 'portugiesen',\n 'joncquen',\n 'tijdelijk',\n 'velzen',\n 'duijvenvoorde',\n 'belois',\n 'vervolch',\n 'gerescontreert',\n 'lieffde',\n 'tulpenburg',\n 'wart',\n 'gracht',\n 'admiraals',\n 'poedecherij',\n 'rotter',\n 'scheijbeek',\n 'aengeb',\n 'lacca',\n 'quelangh',\n 'veldhoen',\n 'gesocht',\n 'arriv',\n 'alblasserdam',\n 'meijnde',\n 'stolle',\n 'maeckten',\n 'ginck',\n 'geluckigh',\n 'dinsdagh',\n 'vlieger',\n 'tijger',\n 'xula',\n 'haij',\n 'naegelen',\n 'haring',\n 'hoochste',\n 'brenght',\n 'veerman',\n 'swaen',\n 'swol',\n 'diana',\n 'bentvelt',\n 'laus',\n 'bogaert',\n ...]</pre> In\u00a0[24]: Copied! <pre>for i in w2v.most_similar(\"regen\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"regen\", topn=100):     print(i[0], end=\" | \") <pre>reegen | regens | reegens | droogte | continueelen | regentijd | hitte | hette | afwatering | continuelen | felle | travaden | regentijt | heete | koude | opperwater | sonneschijn | weste | swaren | buijen | vloed | overvloedigen | regenbuijen | coortse | gestadigen | onstuijmig | doorbreken | regenen | afwateringe | weir | stilte | waijende | westelijke | pides | onweer | vlagen | warmte | tegenwinden | noorde | regenagtig | koortsen | aardbeving | ooste | winden | stormwinden | sneeuw | stroomen | oostelijke | veroorsaakte | dampen | opkomende | stormen | doorwaijende | valwinden | oostewinden | vloet | waaijende | koors | stiltens | winde | vaarbaar | lucht | doorwaijen | hete | stromen | getij | doorblasende | regenagtigh | tegenwind | fellen | geduurigen | delugt | swaaren | moussom | reegentijd | vuurberg | suijdweste | stilten | inbreeken | ongestadig | aanwakkerende | overkroptheijt | aartrijk | westelijcke | ongemeenen | defelle | kentering | broeijende | weerligt | continuele | afwateringen | swaeren | doorstaande | schrale | zuijde | begonde | verlopen | reegenen | noordweste | handsaam | </pre> In\u00a0[25]: Copied! <pre>for i in w2v.most_similar(\"schipbreuk\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"schipbreuk\", topn=100):     print(i[0], end=\" | \") <pre>machteloos | jammerlijk | honger | uijtgestaen | breuk | ongemak | schade | tempeest | onweer | accident | aardbevingh | ongeluk | orcaan | onveer | amsters | calamiteijt | koorts | woedend | crimiineelen | brandinge | gesucceld | schaade | ongemack | onweder | schaede | vreese | deerlyk | storm | uitgestaan | swaaren | ongeluck | bhuij | rampe | elende | besprongen | tanjepoer | ellendig | orcanen | vesemente | zeerampen | vrees | nootweer | stormen | geblasen | ongebal | geplaegt | gewopen | aardbeving | vesementen | presumeerden | uijtwendig | aardbevinge | jarigie | storme | hartseer | monding | deerlijck | vreeze | travade | gewaeijt | stooting | affront | eytmatrauw | stoting | ellende | mack | arrepo | deerlijk | bloedigen | naod | vrese | travaat | vruchte | uijtgestaane | louter | swaeren | smaadheden | travaet | pachtert | travaden | holgaende | smaet | dewijlen | flaauwten | aensegen | boegh | onweeder | belaglijk | nagejaagt | gaets | hongersnoot | hottentoosen | inflamatie | onderlek | losson | nederlage | rotterdame | tcelamse | verbolgen | jaagt | </pre> In\u00a0[26]: Copied! <pre>for i in w2v.most_similar(\"pieter\", topn=100):\n    print(i[0], end=\" | \")\n</pre> for i in w2v.most_similar(\"pieter\", topn=100):     print(i[0], end=\" | \") <pre>gerrit | cornelis | paulus | ian | leendert | barent | jan | evert | andries | lourens | claas | marten | daniel | roeloff | anthonij | dirk | harmanus | theunis | lambert | joost | sijmon | roelof | albert | martinus | gillis | michiel | matthijs | jacob | maerten | govert | maarten | harmen | abraham | iacobus | johannes | volkert | carsten | barend | dirck | rijnier | huijbert | jacobus | hendrick | jasper | abram | egbert | jurriaan | christiaen | sijbrand | verhoef | siewert | arnoldus | laurens | samuel | anthoni | iacob | nicolaas | meijndert | marinus | lucas | coert | iurriaan | hermanus | gerbrant | bartholomeus | henderik | iohannes | isaak | jochem | christiaan | eldert | harman | amos | reijer | guilliam | ioost | gilles | david | antonij | hendrik | reijndert | corthals | hend | bartel | aarnout | arent | casper | joris | jurriaen | coenraet | johannis | adam | adriaen | noach | adriaan | poulus | warnar | anthony | wessel | iurriaen | </pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#word2vec-experiment","title":"Word2Vec Experiment\u00b6","text":""},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#data","title":"Data\u00b6","text":"<p>The data can be downloaded from the GLOBALISE Dataverse: https://datasets.iisg.amsterdam/dataverse/globalise. For this experiment, we're working with version V2.0 of the Transcription dataset:</p> <ul> <li>GLOBALISE project, 2024, \"VOC transcriptions v2 - GLOBALISE\", https://hdl.handle.net/10622/LVXSBW, IISH Data Collection</li> </ul> <p>The project conveniently provides a file with pointers to all txt files in this dataset that we can download automatically. We are using <code>wget</code> to download the files. First the file with pointers, which we will use to download all txt files. This can take a while.</p>"},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#pre-processing","title":"Pre-processing\u00b6","text":""},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#processing","title":"Processing\u00b6","text":""},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#loading-a-pretrained-model","title":"Loading a pretrained model\u00b6","text":"<p>There's a slight difference in what we generate above, and what we can load below. To streamline the commands, we load it as a KeyedVectors object. Also, this is the place to load an earlier trained model.</p>"},{"location":"experiments/GLOBALISE_Word2Vec_Lab/#analysis","title":"Analysis\u00b6","text":""},{"location":"experiments/blacklab-search-interface-general-missives/","title":"BlackLab Search Interface for the General Missives of the VOC","text":"<p>Date: 2021 (pre-GLOBALISE) URL: https://corpora.ato.ivdnt.org/corpus-frontend/Missiven/search Status: Production People involved: Sophie Arnoult, Jesse de Does, Dirk Roorda, Jan Niestadt, Lodewijk Petram, Piek Vossen, Jessica den Oudsten, Dani\u00ebl Tuik</p> <p>A BlackLab search environment offers a new way to explore the General Missives of the Dutch East India Company (VOC). These reports, sent from Batavia (Jakarta) to the Dutch Republic between 1610 and 1795, are now accessible for in-depth research thanks to efforts within the CLARIAH project by a team from VU University, the Huygens Institute, and the Dutch Language Institute. Utilizing advanced OCR and Named Entity Recognition techniques<sup>1</sup>, the team enhanced these documents with metadata and structural elements, including annotations for entities like persons and locations.</p> <p>The BlackLab interface facilitates computational analysis and robust search capabilities of the enriched texts. Researchers can now perform complex syntactic searches or simple keyword queries, uncovering nuanced historical and linguistic insights. A slightly cleaner version of the same corpus is also available as a Text-Fabric resource.</p> <p> https://corpora.ato.ivdnt.org/corpus-frontend/Missiven/search</p> <p>The General Missives summarize the information contained in the Overgekomen Brieven en Papieren series of documents from the VOC archives that the GLOBALISE project aimes to unlock for in-depth research. The corpus available in the BlackLab environment is a selection of General Missives from the period 1610-1767 that was transcribed, edited and published in 14 (digital) book volumes by the Huygens Institute and its predecessors. The original volumes are also available online. </p> <p>Please note that the General Missives contain labels, characterizations and information about persons, actions and events that may be offensive and troubling to individuals and communities.</p> <ol> <li> <p>Sophie I. Arnoult, Lodewijk Petram, and Piek Vossen. 2021. Batavia asked for advice. Pretrained language models for Named Entity Recognition in historical texts. In Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 21\u201330, Punta Cana, Dominican Republic (online). Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.latechclfl-1.3 \u21a9</p> </li> </ol>"},{"location":"experiments/htr-viewer/","title":"GLOBALISE Transcriptions Viewer","text":"<p>Date: October 4, 2023 URL: https://transcriptions.globalise.huygens.knaw.nl/ Status: Prototype People involved: Sebastiaan van Daalen, Hayco de Jong, Bram Buitendijk, Hennie Brugman, Arno Bosse, Leon van Wissen, Lodewijk Petram</p> <p>The aim of the GLOBALISE project is to facilitate research with the Overgekomen Brieven en Papieren series of documents from the VOC archives. As a first step to reaching this goal, we generate transcriptions of the c. 5 million of handwritten pages made available by the Dutch National Archives using automatic transcription software. </p> <p>While we publish text files of the transcriptions on the GLOBALISE Dataverse, we also experiment with building an interface for easy searching and exploring the material. A first prototype can be accessed through the link below. Please share your feedback through our contact form. In the future, improved versions will be made available.</p> <p> https://transcriptions.globalise.huygens.knaw.nl/</p> <p>The collection of archival documents made available in the viewer comprises inventory numbers 1053-4454 and 7527-11024 from the VOC archives, National Archives, The Hague. The scans of the original documents (n=4,802,212) from the period 1610-1796 are available on the website of the National Archives.</p> <p>Please note that the transcriptions will contain errors. They have not been manually checked for accuracy or completeness. Some labels, characterizations and information about persons, actions and events may be offensive and troubling to individuals and communities. Be careful when relying on these transcriptions and be aware of their limitations.</p>"},{"location":"experiments/places-visualization/","title":"GLOBALISE Places Visualization","text":"<p>Date: May 2023 URL: https://globalise.shinyapps.io/mapping_places/ Status: Prototype People involved: Ruben Land</p> <p>Initially as an intern at the GLOBALISE project and now as a student assistant, Ruben Land is working on a dataset of places that occur in the Overgekomen Brieven en Papieren series of VOC documents. He uses R Shiny to create interactive visualizations of his work. These can be accessed by clicking the image below.</p> <p> https://globalise.shinyapps.io/mapping_places/</p>"},{"location":"experiments/skosmos-concept-browser/","title":"Thesaurus concepts browser","text":"<p>We\u2019re working on developing a GLOBALISE thesaurus with definitions of concepts that occur in the Overgekomen Brieven en Papieren series of VOC documents. A preliminary version of the thesaurus can be explored in our SKOSMOS environment.<sup>1</sup></p> <p>Please note that the thesaurus is constantly being improved and extended, and the the URIs in the current version are not stable.</p> <p></p> <ol> <li> <p>This demo is running the SKOSMOS software, developed by the National Library of Finland, to provide a user-friendly interface to our thesaurus. The SKOSMOS software is open source and available on GitHub.\u00a0\u21a9</p> </li> </ol>"},{"location":"experiments/text-fabric-general-missives/","title":"Text-Fabric Serialization of the General Missives of the VOC","text":"<p>Date: 2022 (pre-GLOBALISE) URL: https://clariah.github.io/wp6-missieven-search/text/index.html and https://github.com/CLARIAH/wp6-missieven/ Status: Demo People involved: Dirk Roorda, Sophie Arnoult, Lodewijk Petram, Piek Vossen, Jesse de Does, Jessica den Oudsten, Dani\u00ebl Tuik</p> <p>A Text-Fabric representation of the General Missives of the Dutch East India Company (VOC) offers a new way to explore and analyze these reports. The General Missives sent from Batavia (Jakarta) to the Dutch Republic between 1610 and 1795, are now accessible for in-depth research thanks to efforts within the CLARIAH project by a team from VU University, the Huygens Institute, and the Dutch Language Institute. Utilizing advanced OCR and Named Entity Recognition techniques <sup>1</sup>, the team enhanced these documents with metadata and structural elements, including annotations for entities like persons and locations.</p> <p>The Text-Fabric serialization of the enriched texts is especially suited for linguistic analysis with computational methods. Users can explore the materials in the Text-Fabric search interface or by using the Text-Fabric Python package. A slightly less cleaned version of the same corpus is also available in a BlackLab search environment.</p> <p> https://clariah.github.io/wp6-missieven-search/text/index.html</p> <p>The General Missives summarize the information contained in the Overgekomen Brieven en Papieren series of documents from the VOC archives that the GLOBALISE project aimes to unlock for in-depth research. The corpus available in the BlackLab environment is a selection of General Missives from the period 1610-1767 that was transcribed, edited and published in 14 (digital) book volumes by the Huygens Institute and its predecessors. The original volumes are also available online. </p> <p>Please note that the General Missives contain labels, characterizations and information about persons, actions and events that may be offensive and troubling to individuals and communities.</p> <ol> <li> <p>Sophie I. Arnoult, Lodewijk Petram, and Piek Vossen. 2021. Batavia asked for advice. Pretrained language models for Named Entity Recognition in historical texts. In Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 21\u201330, Punta Cana, Dominican Republic (online). Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.latechclfl-1.3 \u21a9</p> </li> </ol>"}]}